# ğŸµ Music Genre Classifier

A Streamlit-based music genre classifier using the FMA dataset with multiple model architectures.

## âœ¨ Features

- **ğŸ¯ Real-time Classification**: Upload audio files and get instant genre predictions
- **ğŸ—ºï¸ Interactive Visualization**: UMAP embeddings showing music genre landscape
- **ğŸ“Š Comprehensive Analysis**: Feature extraction and model performance insights
- **ğŸ”„ Multiple Models**: Choose between Simple CNN demo model and high-performance models
- **ğŸ§ Multi-format Support**: WAV, MP3, FLAC, M4A audio files

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone https://github.com/rithulkamesh/music_classifier
cd music_classifier

# Set up environment with uv
uv venv
source .venv/bin/activate
uv pip install -e .

# Train a quick demo model (~1-2 minutes)
chmod +x scripts/train_simple_cnn.sh
./scripts/train_simple_cnn.sh

# Run the Streamlit app
uv run streamlit run src/app.py
```

### ğŸ§ NixOS Users

If you're using NixOS and encounter issues with audio libraries, use the provided Nix shell:

```bash
# Use the nix shell environment
nix-shell shell.nix

# Inside the nix-shell, run the app
uv run streamlit run src/app.py
```

## ğŸ“‚ Project Structure

```
music_classifier/
â”œâ”€â”€ scripts/                  # Training scripts
â”‚   â”œâ”€â”€ train_simple_cnn.py   # Simple CNN model training script
â”‚   â””â”€â”€ train_simple_cnn.sh   # Training shell script
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ app.py                # Main Streamlit application
â”‚   â”œâ”€â”€ audio_processing.py   # Audio feature extraction
â”‚   â”œâ”€â”€ data_loader.py        # FMA dataset loading & preprocessing
â”‚   â”œâ”€â”€ models.py             # Neural network model architectures
â”‚   â”œâ”€â”€ preprocess.py         # Data preprocessing script
â”‚   â””â”€â”€ train.py              # Model training core functionality
â”œâ”€â”€ data/                     # Data directory
â”‚   â”œâ”€â”€ fma_medium/           # FMA Medium audio files
â”‚   â”œâ”€â”€ fma_metadata/         # FMA metadata files
â”‚   â”œâ”€â”€ embeddings/           # UMAP embeddings
â”‚   â”‚   â”œâ”€â”€ umap_embeddings.pkl        # UMAP embeddings for visualization
â”‚   â”‚   â””â”€â”€ umap_visualization.png     # Pre-generated UMAP plot
â”‚   â””â”€â”€ preprocessed/         # Preprocessed features
â”œâ”€â”€ checkpoints/              # Trained model checkpoints
â””â”€â”€ pyproject.toml            # Dependencies and project metadata
```

## ğŸ“Š Data Directory Structure

```
data/
â”œâ”€â”€ fma_medium/           # Free Music Archive dataset (audio files)
â”œâ”€â”€ fma_metadata/         # FMA metadata files
â”œâ”€â”€ preprocessed/         # Processed audio features
â”œâ”€â”€ embeddings/           # UMAP visualization data
â”‚   â”œâ”€â”€ umap_embeddings.pkl        # UMAP embeddings for visualization
â”‚   â””â”€â”€ umap_visualization.png     # Pre-generated UMAP plot
â”œâ”€â”€ samples/              # Sample audio files for testing
â””â”€â”€ genre_names.json      # Genre name mappings
```

## ğŸµ Models

### Simple CNN Demo Model

- **Architecture**: 52 â†’ 512 â†’ 512 â†’ 256 â†’ 128 â†’ 13
- **Training Time**: 1-2 minutes
- **Accuracy**: Loads dynamically from model checkpoint
- **Best For**: Quick demos and testing

### High-Performance Model (Advanced)

- **Architecture**: Deep residual connections with attention
- **Features**: Spectrogram-based with transfer learning
- **Training Time**: ~10-15 minutes with optimizations
- **Accuracy**: 98.6% target
- **Best For**: Production use and highest accuracy

## ğŸ”§ Usage

### Training Models

```bash
# Train a quick demo model
./scripts/train_simple_cnn.sh

# Train the high-performance model (takes longer)
uv run python src/run_training.py
```

### Running the App

```bash
# Start the Streamlit app
uv run streamlit run src/app.py
```

## ğŸµ Audio Features (52 total)

- **MFCC (39)**: 13 coefficients + 13 delta + 13 deltaÂ²
- **Spectral (8)**: Centroid, rolloff, ZCR, bandwidth (mean/std)
- **Harmonic (4)**: 12 chroma features + tempo
- **Temporal (1)**: Onset strength + RMS energy

## ğŸ¯ Supported Genres

The model classifies 13 genres including Blues, Classical, Country, Electronic, Folk, Hip-Hop, Jazz, Pop, Rock, Soul-RnB, and others.

## ï¿½ï¸ Requirements

- Python 3.11+
- PyTorch 2.0+
- Streamlit
- Librosa
- UMAP-learn
- Plotly

All dependencies are managed with `uv` for fast, reliable dependency management.

---

**Built with â¤ï¸ using modern ML techniques for audio processing**
